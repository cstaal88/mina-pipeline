# .github/workflows/fetch.yml
# Automated MediaCloud news collection pipeline
#
# Triggered via cron-job.org - runs BOTH topics sequentially
# Each run collects and cleans news for all topics, then uploads to gists

name: "MediaCloud News Pipeline"

on:
  workflow_dispatch:
    inputs:
      topic:
        description: 'Topic to collect (leave empty for ALL topics)'
        required: false
        default: ''

concurrency:
  group: mcloud-fetch
  cancel-in-progress: true

jobs:
  fetch-and-update-gist:
    runs-on: ubuntu-latest
    timeout-minutes: 90

    env:
      MEDIACLOUD_API_KEY: ${{ secrets.MEDIACLOUD_API_KEY }}
      GH_TOKEN: ${{ secrets.GIST_PAT }}

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install dependencies
        run: |
          python3 -m pip install --upgrade pip
          python3 -m pip install mediacloud python-dotenv
          python3 -m pip install requests beautifulsoup4 lxml tqdm tenacity typer

      - name: Run pipeline for all topics
        run: |
          # Determine which topics to run
          INPUT_TOPIC="${{ github.event.inputs.topic }}"
          
          if [ -n "$INPUT_TOPIC" ]; then
            # Single topic specified
            TOPICS="$INPUT_TOPIC"
          else
            # Run all topics
            TOPICS="minneapolis-ice greenland-trump"
          fi
          
          echo "=== Running pipeline for topics: $TOPICS ==="
          
          for TOPIC in $TOPICS; do
            echo ""
            echo "========================================"
            echo "TOPIC: $TOPIC"
            echo "Started: $(date -u +%Y-%m-%d' '%H:%M' UTC')"
            echo "========================================"
            
            # Get gist ID for this topic
            case "$TOPIC" in
              "minneapolis-ice")
                GIST_ID="839f9f409d36d715d277095886ced536"
                ;;
              "greenland-trump")
                GIST_ID="a046f4a9233ff2e499dfeb356e081d79"
                ;;
              *)
                echo "Unknown topic: $TOPIC - skipping"
                continue
                ;;
            esac
            
            # Download existing clean data
            CLEAN_DIR="clean"
            mkdir -p "$CLEAN_DIR"
            if gh gist view "$GIST_ID" -f "clean.jsonl" > "$CLEAN_DIR/articles-${TOPIC}.jsonl" 2>/dev/null; then
              EXISTING=$(wc -l < "$CLEAN_DIR/articles-${TOPIC}.jsonl")
              echo "Downloaded $EXISTING existing clean records"
            else
              echo "No existing clean data"
              touch "$CLEAN_DIR/articles-${TOPIC}.jsonl"
            fi
            
            # Run pipeline
            python3 run-pipeline.py --topic "$TOPIC" --auto || echo "Pipeline for $TOPIC exited with code $?"
            
            # Upload results
            CLEAN_FILE="$CLEAN_DIR/articles-${TOPIC}.jsonl"
            if [ -f "$CLEAN_FILE" ]; then
              echo "Uploading clean.jsonl to gist..."
              gh gist edit "$GIST_ID" -f "clean.jsonl" "$CLEAN_FILE"
              echo "âœ“ Gist updated: https://gist.github.com/$GIST_ID"
            fi
            
            echo "Completed: $TOPIC"
          done
          
          echo ""
          echo "=== All topics completed ==="

      - name: Summary
        if: always()
        run: |
          echo "================================================"
          echo "MediaCloud Pipeline Completed"
          echo "Date: $(date -u +%Y-%m-%d' '%H:%M' UTC')"
          echo "================================================"
